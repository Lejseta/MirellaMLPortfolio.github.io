{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mirella\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 202ms/step - accuracy: 0.7123 - loss: 0.5293 - val_accuracy: 0.8497 - val_loss: 0.3428\n",
      "Epoch 2/5\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 185ms/step - accuracy: 0.8876 - loss: 0.2689 - val_accuracy: 0.8486 - val_loss: 0.3397\n",
      "Epoch 3/5\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 215ms/step - accuracy: 0.9149 - loss: 0.2151 - val_accuracy: 0.8512 - val_loss: 0.3567\n",
      "Epoch 4/5\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 210ms/step - accuracy: 0.9310 - loss: 0.1786 - val_accuracy: 0.8517 - val_loss: 0.3757\n",
      "Epoch 5/5\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 207ms/step - accuracy: 0.9452 - loss: 0.1434 - val_accuracy: 0.8484 - val_loss: 0.4248\n",
      "167/167 - 4s - 23ms/step - accuracy: 0.8484 - loss: 0.4248\n",
      "Test Accuracy: 84.84%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
      "Not Sarcastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    headlines = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Load each line as a separate JSON object\n",
    "            data = json.loads(line)\n",
    "            headlines.append(data['headline'])\n",
    "            labels.append(1 if data['is_sarcastic'] == 1 else 0)\n",
    "    return pd.DataFrame({'headline': headlines, 'label': labels})\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = load_data('../datasets/Sarcasm_Headlines_Dataset.json')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df['headline']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data\n",
    "max_words = 5000  # Vocabulary size\n",
    "max_sequence_length = 100  # Length of input sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_sequence_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score, accuracy = model.evaluate(X_test_pad, y_test, verbose=2)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_sarcasm(headline):\n",
    "    sequence = tokenizer.texts_to_sequences([headline])\n",
    "    padded = pad_sequences(sequence, maxlen=max_sequence_length)\n",
    "    prediction = model.predict(padded)\n",
    "    return \"Sarcastic\" if prediction > 0.5 else \"Not Sarcastic\"\n",
    "\n",
    "# Example usage\n",
    "print(predict_sarcasm(\"I love waiting in long lines!\"))  # Sarcastic example\n",
    "print(predict_sarcasm(\"I can't wait to go to the beach!\"))  # Non-sarcastic example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
